## 技術手冊（Ragic ERP 資料備份系統）

本手冊面向技術維運人員，完整說明系統架構、模組、主要函數、變數及部署要點。

### 1. 系統架構與資料流
- Ragic API（來源）→ `ragic_client.py` 取數（單頁抓取 + 本地過濾 + 自動翻頁）
- `data_transformer.py` 進行欄位對應與型別正規化、Invalid 收集
- `bigquery_uploader.py` 上傳到 BigQuery（直送 MERGE/INSERT 或 staging+SP）
- `erp_backup_main.py` 串起整體流程，並寄送郵件（`email_notifier.py`）

### 2. 環境變數（關鍵）
- RAGIC_API_KEY：Ragic Base64 API Key
- RAGIC_ACCOUNT：Ragic 帳號（子網域）
- RAGIC_SHEET_ID：單表 ID 或 `ALL`（多表）
- SHEET_MAP_JSON：`sheet_code→sheet_id` 對照（JSON 字串）
- GCP_PROJECT_ID：GCP 專案 ID
- BIGQUERY_DATASET/BIGQUERY_TABLE/BIGQUERY_LOCATION：BigQuery 目標
- LAST_MODIFIED_FIELD_NAMES：最後修改欄位名稱候選（逗號分隔）
- RAGIC_MAX_PAGES/RAGIC_PAGE_SIZE：API 分頁控制（大表會自動提升 limit）
- UPLOAD_MODE/BATCH_THRESHOLD：上傳模式與門檻（auto 或 staging_sp）
- NOTIFICATION_EMAIL/SMTP_FROM_EMAIL/SMTP_FROM_PASSWORD：郵件

### 3. 模組與主要函數

#### 3.1 `ragic_client.py`
- 類別：`RagicClient(api_key: str, account: str, timeout=30, max_retries=3)`
  - `test_connection() -> bool`：測試 API 可用
  - `fetch_since_local_paged(sheet_id: str, since_dt: datetime, last_modified_field_names: List[str], until_dt: Optional[datetime]=None, limit: int=1000, max_pages: int=50) -> List[Dict]`
    - 單頁抓取，本地以日期欄位解析後過濾；翻頁條件：若當頁沒有「一週外」資料則往下一頁
    - 邊界：嚴格 `dt > since`，若提供 `until_dt` 則 `dt <= until_dt`

#### 3.2 `data_transformer.py`
- 工廠：`create_transformer(sheet_code: Optional[str]=None, project_id: Optional[str]=None, use_dynamic_mapping=False)`
- 類別：`DataTransformer`
  - `transform_data(records: List[Dict]) -> List[Dict]`：欄位對應與型別轉換
  - `get_invalid_records() -> List[Dict]`：取得 Invalid 清單（含 index、errors、raw）
- `BIGQUERY_SCHEMA`：完整目標 Schema（含 `sheet_code`）

#### 3.3 `bigquery_uploader.py`
- 類別：`BigQueryUploader(project_id: str, location: str="US")`
  - `upload_data(data, dataset_id, table_id, schema=None, use_merge=True, upload_mode="auto", batch_threshold=5000, staging_table=None, merge_sp_name=None) -> Dict`
    - `auto`：小量直送（MERGE 或 INSERT）；超過門檻使用 staging+SP
  - `get_last_sync_timestamp(dataset_id, table_id) -> str`：取得最後同步時間（無資料則回傳一週前）
- 其他：`_ensure_dataset_exists()`、`_ensure_table_exists()`、`_upload_with_merge()`、`_upload_with_insert()`、`_upload_via_staging()`

#### 3.4 `erp_backup_main.py`
- 類別：`ERPBackupManager(config: Dict[str, Any])`
  - `run_backup() -> Dict`：單表流程（以 `ragic_sheet_id` 指定）
  - `run_backup_all_sheets() -> Dict`：多表流程（9 張表）
  - `fetch_ragic_data(last_sync_time: str) -> list`：單表抓取（local paged incremental）
  - `fetch_ragic_data_for_sheet(sheet_id, last_sync_time, last_modified_names=None, limit=None, max_pages=None) -> list`
  - `transform_data()`、`upload_to_bigquery()`、`get_last_sync_timestamp()`
  - `backup_erp_data(request)`：Cloud Function 入口（HTTP）

#### 3.5 `email_notifier.py`
- `send_backup_notification(project_id: str, to_email: str, backup_result: Dict, smtp_config: Dict) -> bool`
  - 郵件內容：總筆數、每表筆數、執行時間、錯誤摘要（若有）

### 4. 增量與去重策略（重要）
- 若可取得各表「最後修改」欄位 ID：使用 Ragic `where=<欄位ID>,gt,<時間>`
- 若不可：採單頁抓取 + 本地過濾一週；翻頁規則：當頁沒有一週外資料→往下一頁
- 邊界：嚴格 `dt > last_sync`；可選 `until` 上界以切割相鄰時間窗
- 驗證腳本：`test/run_api_incremental_window.py`（同邏輯已納入正式程式）

### 5. 部署（Cloud Functions）
- 腳本：`scripts/migrate_to_gcp_cf.sh`（最小必要部署，會建立/檢查 Dataset，部署 CF 與 Scheduler）
- 入口：`backup_erp_data`
- 設定：以 `--set-env-vars` 注入所有必要參數

### 6. 操作維護
- 觀測：Cloud Logging（invalid 記錄、備份摘要）
- 查詢：BigQuery `erp_backup.ragic_data`（可用 `sheet_code` 分組）
- 修復：Ragic 後台或 API 依 `_ragicId` 修正資料，下次備份自動納入

### 7. 版本控管與安全
- 機密只經由環境變數注入（不入庫）
- `.gcloudignore` 排除 `test/`, `documents/`, `.claude/` 等非必要內容
- 最小權限：BQ Data Editor、BQ Job User、Logging Writer、CF Admin/Invoker

### 8. 常見錯誤與排除
- `where` 取不到增量：改用本地過濾路徑並確認「最後修改」欄位清單
- MERGE 出錯：自動改用 INSERT；或改 staging+SP（`UPLOAD_MODE=staging_sp`）
- Email 連線：檢查 SMTP 帳密與 2FA 應用密碼

---
如需更深入細節，請參考原始碼與 README 對應章節。此手冊將隨版本更新同步維護。


